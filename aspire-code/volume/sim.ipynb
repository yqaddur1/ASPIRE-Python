{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-06 19:05:46,069 INFO [aspire.volume.volume] map-data/emd_14930.map.gz with dtype float32 loaded as <class 'numpy.float64'>\n",
      "2023-03-06 19:05:54,015 INFO [aspire.source.image] Creating Simulation with 10000 images.\n",
      "2023-03-06 19:05:54,073 INFO [aspire.source.simulation] Appending CustomNoiseAdder to generation pipeline\n",
      "2023-03-06 19:05:54,077 INFO [aspire.source.image] Perform phase flip on source object\n",
      "2023-03-06 19:05:54,078 INFO [aspire.source.image] Adding Phase Flip Xform to end of generation pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-06 19:05:54,109 INFO [aspire.nufft] Trying NFFT backend cufinufft\n",
      "2023-03-06 19:05:54,113 INFO [aspire.nufft] NFFT backend cufinufft not usable:\n",
      "\tNo module named 'pycuda'\n",
      "2023-03-06 19:05:54,114 INFO [aspire.nufft] Trying NFFT backend finufft\n",
      "2023-03-06 19:05:54,134 INFO [aspire.nufft] NFFT backend finufft usable.\n",
      "2023-03-06 19:05:54,135 INFO [aspire.nufft] Trying NFFT backend pynfft\n",
      "2023-03-06 19:05:54,137 INFO [aspire.nufft] NFFT backend pynfft not usable:\n",
      "\tNo module named 'pynfft'\n",
      "2023-03-06 19:05:54,139 INFO [aspire.nufft] Selected NFFT backend = finufft.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:26<00:00,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-06 19:06:20,972 INFO [aspire.source.image] Whitening source object\n",
      "2023-03-06 19:06:20,973 INFO [aspire.source.image] Transforming all CTF Filters into Multiplicative Filters\n",
      "2023-03-06 19:06:20,975 INFO [aspire.source.image] Adding Whitening Filter Xform to end of generation pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from aspire.source import Simulation\n",
    "from aspire.basis import FSPCABasis\n",
    "from aspire.volume import Volume\n",
    "import logging\n",
    "from aspire.noise import AnisotropicNoiseEstimator, CustomNoiseAdder\n",
    "from aspire.operators import FunctionFilter, RadialCTFFilter\n",
    "import numpy as np\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "interactive = True  # Draw blocking interactive plots?\n",
    "do_cov2d = False  # Use CWF coefficients\n",
    "img_size = 32  # Downsample the volume to a desired resolution\n",
    "num_imgs = 10000  # How many images in our source.\n",
    "n_classes = 1000  # How many class averages to compute.\n",
    "n_nbor = 10  # How many neighbors to stack\n",
    "noise_variance = 5e-7  # Set a target noise variance\n",
    "\n",
    "og_v = Volume.load(\"map-data/emd_14930.map.gz\", dtype=np.float64)\n",
    "v = og_v.downsample(img_size)\n",
    "L = v.resolution\n",
    "def noise_function(x, y):\n",
    "    alpha = 1\n",
    "    beta = 1\n",
    "    # White\n",
    "    f1 = noise_variance\n",
    "    # Violet-ish\n",
    "    f2 = noise_variance * (x * x + y * y) / L * L\n",
    "    return (alpha * f1 + beta * f2) / 2.0\n",
    "custom_noise = CustomNoiseAdder(noise_filter=FunctionFilter(noise_function))\n",
    "pixel_size = 5 * 65 / img_size  # Pixel size of the images (in angstroms)\n",
    "voltage = 200  # Voltage (in KV)\n",
    "defocus_min = 1.5e4  # Minimum defocus value (in angstroms)\n",
    "defocus_max = 2.5e4  # Maximum defocus value (in angstroms)\n",
    "defocus_ct = 7  # Number of defocus groups.\n",
    "Cs = 2.0  # Spherical aberration\n",
    "alpha = 0.1  # Amplitude contrast\n",
    "ctf_filters = [\n",
    "    RadialCTFFilter(pixel_size, voltage, defocus=d, Cs=2.0, alpha=0.1)\n",
    "    for d in np.linspace(defocus_min, defocus_max, defocus_ct)\n",
    "]\n",
    "\n",
    "# Finally create the Simulation\n",
    "src = Simulation(\n",
    "    L=v.resolution,\n",
    "    n=num_imgs,\n",
    "    vols=v,\n",
    "    noise_adder=custom_noise,\n",
    "    unique_filters=ctf_filters,\n",
    "    dtype=v.dtype,\n",
    ")\n",
    "\n",
    "\n",
    "src.phase_flip()\n",
    "aiso_noise_estimator = AnisotropicNoiseEstimator(src)\n",
    "src.whiten(aiso_noise_estimator.filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-06 19:06:21,061 INFO [aspire.basis.ffb_2d] Expanding 2D image in a frequency-domain Fourier–Bessel basis using the fast method.\n",
      "2023-03-06 19:06:21,125 INFO [aspire.basis.fspca] Estimating the noise of images.\n",
      "2023-03-06 19:06:21,126 INFO [aspire.noise.noise] Determining Noise variance in batches of 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:25<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-06 19:06:46,500 INFO [aspire.noise.noise] Noise variance = 0.9657965548819362\n",
      "2023-03-06 19:06:46,501 INFO [aspire.basis.fspca] Setting noise_var=0.9657965548819362\n",
      "2023-03-06 19:06:46,503 INFO [aspire.covariance.covar2d] Represent CTF filters in FB basis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-06 19:07:17,712 WARNING [aspire.covariance.covar2d] Left side b after removing noise in Batched Cov2D is not positive semidefinite.\n",
      "2023-03-06 19:07:18,032 WARNING [aspire.covariance.covar2d] Covariance matrix in Batched Cov2D is not positive semidefinite.\n",
      "2023-03-06 19:07:18,034 INFO [aspire.covariance.covar2d] Convert matrices to positive semidefinite.\n"
     ]
    }
   ],
   "source": [
    "basis = FSPCABasis(src = src, components=400, batch_size=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from scipy.spatial.transform import Rotation as sp_rot\n",
    "\n",
    "sp_rotations = sp_rot.from_matrix(src.rotations)\n",
    "rot_vecs = sp_rotations.as_rotvec()\n",
    "rot_vecs /= np.linalg.norm(rot_vecs, axis=-1)[:,np.newaxis]\n",
    "rot_vecs = torch.from_numpy(rot_vecs)\n",
    "rot_vecs = torch.stack((rot_vecs,rot_vecs), dim=1).view(2*rot_vecs.shape[0],rot_vecs.shape[1])\n",
    "\n",
    "\n",
    "coefs = basis.spca_coef\n",
    "coefs = basis.to_complex(coefs)\n",
    "coefs = torch.from_numpy(coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotvecs_inners = torch.matmul(rot_vecs, torch.transpose(rot_vecs,0,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2841255f2d44bd987cf94db06635fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def max_filter_torch(Z, coefs, rotvecs_inners, basis, padding = 400):\n",
    "    num_temp = Z.shape[0]\n",
    "    num_pics = coefs.shape[0]\n",
    "    matrix_result = torch.zeros(num_temp, num_pics*2)\n",
    "\n",
    "    max_filter_bank = []\n",
    "    max_filter_bank_refl = []\n",
    "\n",
    "    for i in range(num_pics):\n",
    "        output = basis.max_filter_bank(coefs[i].numpy(), Z, basis.max_filter_fft, padding)\n",
    "        reg_out = torch.from_numpy(output[0]).view(num_temp,1)\n",
    "        refl_out = torch.from_numpy(output[1]).view(num_temp,1)\n",
    "        matrix_result[:,2*i] = reg_out\n",
    "        matrix_result[:,2*i+1] = refl_out\n",
    "\n",
    "    bank_inners = torch.matmul(torch.transpose(matrix_result), matrix_result)\n",
    "\n",
    "    return torch.linalg.matrix_norm(bank_inners - rotvecs_inners)\n",
    "\n",
    "\n",
    "num_templates = 40\n",
    "lr = 0.1\n",
    "\n",
    "indices = torch.randperm(len(coefs))[:num_templates]\n",
    "coefs_copy = coefs.data.clone()\n",
    "Z = coefs_copy[indices].requires_grad_(True)\n",
    "\n",
    "optim = torch.optim.Adam([Z], lr = lr)\n",
    "\n",
    "steps = 100\n",
    "for s in tqdm(range(steps)):\n",
    "  optim.zero_grad()\n",
    "  W = max_filter_torch(Z, coefs, rotvecs_inners, basis, padding=400)\n",
    "  W.backward()\n",
    "  optim.step()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aspire_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
