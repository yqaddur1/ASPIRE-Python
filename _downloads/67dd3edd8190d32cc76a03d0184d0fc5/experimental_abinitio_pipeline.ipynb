{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Abinitio Pipeline - Experimental Data\n\nThis notebook introduces a selection of\ncomponents corresponding to loading real Relion picked\nparticle Cryo-EM data and running key ASPIRE-Python\nAbinitio model components as a pipeline.\n\nSpecifically this pipeline uses the\nEMPIAR 10028 picked particles data, available here:\n\nhttps://www.ebi.ac.uk/empiar/EMPIAR-10028\n\nhttps://www.ebi.ac.uk/emdb/EMD-10028\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports\nFirst import some of the usual suspects.\nIn addition, import some classes from\nthe ASPIRE package that will be used throughout this experiment.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import logging\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom aspire.abinitio import CLSyncVoting\nfrom aspire.basis import FFBBasis2D, FFBBasis3D\nfrom aspire.classification import BFSReddyChatterjiAverager2D, RIRClass2D\nfrom aspire.denoising import DenoiserCov2D\nfrom aspire.noise import AnisotropicNoiseEstimator\nfrom aspire.reconstruction import MeanEstimator\nfrom aspire.source import RelionSource\n\nlogger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parameters\nExample simulation configuration.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "interactive = False  # Draw blocking interactive plots?\ndo_cov2d = True  # Use CWF coefficients\nn_imgs = 20000  # Set to None for all images in starfile, can set smaller for tests.\nimg_size = 32  # Downsample the images/reconstruction to a desired resolution\nn_classes = 1000  # How many class averages to compute.\nn_nbor = 50  # How many neighbors to stack\nstarfile_in = \"10028/data/shiny_2sets.star\"\nvolume_filename_prefix_out = f\"10028_recon_c{n_classes}_m{n_nbor}_{img_size}.mrc\"\npixel_size = 1.34"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Source data and Preprocessing\n\n`RelionSource` is used to access the experimental data via a `starfile`.\nBegin by downsampling to our chosen resolution, then preprocess\nto correct for CTF and noise.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Create a source object for the experimental images\nsrc = RelionSource(starfile_in, pixel_size=pixel_size, max_rows=n_imgs)\n\n# Downsample the images\nlogger.info(f\"Set the resolution to {img_size} X {img_size}\")\nsrc.downsample(img_size)\n\n# Peek\nif interactive:\n    src.images[:10].show()\n\n# Use phase_flip to attempt correcting for CTF.\nlogger.info(\"Perform phase flip to input images.\")\nsrc.phase_flip()\n\n# Estimate the noise and `Whiten` based on the estimated noise\naiso_noise_estimator = AnisotropicNoiseEstimator(src)\nsrc.whiten(aiso_noise_estimator.filter)\n\n# Plot the noise profile for inspection\nif interactive:\n    plt.imshow(aiso_noise_estimator.filter.evaluate_grid(img_size))\n    plt.show()\n\n# Peek, what do the whitened images look like...\nif interactive:\n    src.images[:10].show()\n\n# # Optionally invert image contrast, depends on data convention.\n# # This is not needed for 10028, but included anyway.\n# logger.info(\"Invert the global density contrast\")\n# src.invert_contrast()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: CWF Denoising\n\nOptionally generate an alternative source that is denoised with `cov2d`,\nthen configure a customized averager. This allows the use of CWF denoised\nimages for classification, but stacks the original images for averages\nused in the remainder of the reconstruction pipeline.\n\nIn this example, this behavior is controlled by the `do_cov2d` boolean variable.\nWhen disabled, the original src and default averager is used.\nIf you will not be using cov2d,\nyou may remove this code block and associated variables.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "classification_src = src\ncustom_averager = None\nif do_cov2d:\n    # Use CWF denoising\n    cwf_denoiser = DenoiserCov2D(src)\n    # Use denoised src for classification\n    classification_src = cwf_denoiser.denoise()\n    # Peek, what do the denoised images look like...\n    if interactive:\n        classification_src.images[:10].show()\n\n    # Use regular `src` for the alignment and composition (averaging).\n    composite_basis = FFBBasis2D((src.L,) * 2, dtype=src.dtype)\n    custom_averager = BFSReddyChatterjiAverager2D(composite_basis, src, dtype=src.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Class Averaging\n\nNow perform classification and averaging for each class.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "logger.info(\"Begin Class Averaging\")\n\nrir = RIRClass2D(\n    classification_src,  # Source used for classification\n    fspca_components=400,\n    bispectrum_components=300,  # Compressed Features after last PCA stage.\n    n_nbor=n_nbor,\n    n_classes=n_classes,\n    large_pca_implementation=\"legacy\",\n    nn_implementation=\"sklearn\",\n    bispectrum_implementation=\"legacy\",\n    averager=custom_averager,\n)\n\nclasses, reflections, distances = rir.classify()\navgs = rir.averages(classes, reflections, distances)\nif interactive:\n    avgs.images[:10].show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Common Line Estimation\n\nNext create a CL instance for estimating orientation of projections\nusing the Common Line with Synchronization Voting method.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "logger.info(\"Begin Orientation Estimation\")\n\norient_est = CLSyncVoting(avgs, n_theta=36)\n# Get the estimated rotations\norient_est.estimate_rotations()\nrots_est = orient_est.rotations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Volume Reconstruction\n\nUsing the estimated rotations, attempt to reconstruct a volume.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "logger.info(\"Begin Volume reconstruction\")\n\n# Assign the estimated rotations to the class averages\navgs.rotations = rots_est\n\n# Create a reasonable Basis for the 3d Volume\nbasis = FFBBasis3D((img_size,) * 3, dtype=src.dtype)\n\n# Setup an estimator to perform the back projection.\nestimator = MeanEstimator(avgs, basis)\n\n# Perform the estimation and save the volume.\nestimated_volume = estimator.estimate()\nestimated_volume.save(volume_filename_prefix_out, overwrite=True)\n\n# Peek at result\nif interactive:\n    plt.imshow(np.sum(estimated_volume[0], axis=-1))\n    plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}